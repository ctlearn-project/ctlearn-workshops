{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86229d1-d81c-44c8-9fdb-214ac6fecb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tjarkmiener/Desktop/ctlearn_workshop/ctlearn_workshop2024/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db6c1486-0427-47a6-8d6d-17af2a3c4dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctapipe                   0.20.0                   pypi_0    pypi\n",
      "# packages in environment at /opt/anaconda3/envs/ctlearn:\n",
      "ctlearn                   0.7.0.post56              dev_0    <develop>\n",
      "dl1-data-handler          0.10.11.post35            dev_0    <develop>\n",
      "tensorflow                2.15.1                   pypi_0    pypi\n",
      "tensorflow-estimator      2.15.0                   pypi_0    pypi\n",
      "tensorflow-io-gcs-filesystem 0.37.0                   pypi_0    pypi\n"
     ]
    }
   ],
   "source": [
    "! conda list | grep ctapipe\n",
    "! conda list | grep ctlearn\n",
    "! conda list | grep dl1-data-handler \n",
    "! conda list | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d543472c-79b5-4549-84a0-976365a2c964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2G\t../data/R1DL1_merged/gamma_theta_16.087_az_108.090_runs1-2.r1.dl1.h5\r\n",
      "1.3G\t../data/R1DL1_merged/gamma_theta_16.087_az_108.090_runs3-4.r1.dl1.h5\r\n",
      "163M\t../data/R1DL1_merged/proton_theta_16.087_az_108.090_runs1-2.r1.dl1.h5\r\n",
      "147M\t../data/R1DL1_merged/proton_theta_16.087_az_108.090_runs3-4.r1.dl1.h5\r\n",
      "160M\t../data/R1DL1_merged/proton_theta_16.087_az_108.090_runs5-6.r1.dl1.h5\r\n",
      "1.3G\t../data/R1DL1_merged/test/gamma-diffuse\r\n",
      "385M\t../data/R1DL1_merged/test/proton\r\n",
      "1.7G\t../data/R1DL1_merged/test\r\n"
     ]
    }
   ],
   "source": [
    "! du -h ../data/R1DL1_merged/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe24c2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ctlearn [-h] [--config_file CONFIG_FILE] [--input INPUT [INPUT ...]]\r\n",
      "               [--pattern PATTERN [PATTERN ...]] [--mode MODE]\r\n",
      "               [--output OUTPUT] [--reco RECO [RECO ...]]\r\n",
      "               [--default_model DEFAULT_MODEL] [--clean | --no-clean]\r\n",
      "               [--nsb | --no-nsb] [--pretrained_weights PRETRAINED_WEIGHTS]\r\n",
      "               [--prediction_directory PREDICTION_DIRECTORY]\r\n",
      "               [--tel_types TEL_TYPES [TEL_TYPES ...]]\r\n",
      "               [--allowed_tels ALLOWED_TELS [ALLOWED_TELS ...]]\r\n",
      "               [--size_cut SIZE_CUT] [--leakage_cut LEAKAGE_CUT]\r\n",
      "               [--multiplicity_cut MULTIPLICITY_CUT] [--num_epochs NUM_EPOCHS]\r\n",
      "               [--batch_size BATCH_SIZE] [--random_seed RANDOM_SEED]\r\n",
      "               [--log_to_file] [--save2onnx] [--debug]\r\n",
      "\r\n",
      "Train/Predict with a CTLearn model.\r\n",
      "\r\n",
      "options:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --config_file CONFIG_FILE, -c CONFIG_FILE\r\n",
      "                        Path to YAML configuration file with training options\r\n",
      "  --input INPUT [INPUT ...], -i INPUT [INPUT ...]\r\n",
      "                        Input directories (not required when file_list is set\r\n",
      "                        in the config file)\r\n",
      "  --pattern PATTERN [PATTERN ...], -p PATTERN [PATTERN ...]\r\n",
      "                        Pattern to mask unwanted files from the data input\r\n",
      "                        directory\r\n",
      "  --mode MODE, -m MODE  Mode to run CTLearn; valid options: train, predict, or\r\n",
      "                        train_and_predict\r\n",
      "  --output OUTPUT, -o OUTPUT\r\n",
      "                        Output directory, where the logging, model weights and\r\n",
      "                        plots are stored\r\n",
      "  --reco RECO [RECO ...], -r RECO [RECO ...]\r\n",
      "                        Reconstruction task to perform; valid options: type,\r\n",
      "                        energy, direction and/or cherenkov_photons\r\n",
      "  --default_model DEFAULT_MODEL, -d DEFAULT_MODEL\r\n",
      "                        Default CTLearn Model; valid options: SingleCNN, TRN,\r\n",
      "                        rawwaveSingleCNN, rawwaveTRN, calwaveSingleCNN,\r\n",
      "                        calwaveTRN (mono), mergedTRN, and CNNRNN (stereo)\r\n",
      "  --clean, --no-clean   Flag, if the network should be trained with cleaned\r\n",
      "                        images and waveforms (default: False)\r\n",
      "  --nsb, --no-nsb       Flag, if the network should predict on NSB trigger\r\n",
      "                        patches (default: False)\r\n",
      "  --pretrained_weights PRETRAINED_WEIGHTS, -w PRETRAINED_WEIGHTS\r\n",
      "                        Path to the pretrained weights\r\n",
      "  --prediction_directory PREDICTION_DIRECTORY, -y PREDICTION_DIRECTORY\r\n",
      "                        Path to store the CTLearn predictions (optional)\r\n",
      "  --tel_types TEL_TYPES [TEL_TYPES ...], -t TEL_TYPES [TEL_TYPES ...]\r\n",
      "                        Selection of telescope types; valid option:\r\n",
      "                        LST_LST_LSTCam, LST_LST_LSTSiPMCam,\r\n",
      "                        LST_MAGIC_MAGICCam, MST_MST_FlashCam,\r\n",
      "                        MST_MST_NectarCam, SST_1M_DigiCam, SST_SCT_SCTCam,\r\n",
      "                        and/or SST_ASTRI_ASTRICam\r\n",
      "  --allowed_tels ALLOWED_TELS [ALLOWED_TELS ...], -a ALLOWED_TELS [ALLOWED_TELS ...]\r\n",
      "                        List of allowed tel_ids, others will be ignored.\r\n",
      "                        Selected tel_ids will be ignored, when their telescope\r\n",
      "                        type is not selected\r\n",
      "  --size_cut SIZE_CUT, -z SIZE_CUT\r\n",
      "                        Hillas intensity cut to perform\r\n",
      "  --leakage_cut LEAKAGE_CUT, -l LEAKAGE_CUT\r\n",
      "                        Leakage intensity cut to perform\r\n",
      "  --multiplicity_cut MULTIPLICITY_CUT, -u MULTIPLICITY_CUT\r\n",
      "                        Multiplicity cut to perform\r\n",
      "  --num_epochs NUM_EPOCHS, -e NUM_EPOCHS\r\n",
      "                        Number of epochs to train\r\n",
      "  --batch_size BATCH_SIZE, -b BATCH_SIZE\r\n",
      "                        Batch size per worker\r\n",
      "  --random_seed RANDOM_SEED, -s RANDOM_SEED\r\n",
      "                        Selection of random seed (4 digits)\r\n",
      "  --log_to_file         Log to a file in model directory instead of terminal\r\n",
      "  --save2onnx           Save model in an ONNX file\r\n",
      "  --debug               Print debug/logger messages\r\n"
     ]
    }
   ],
   "source": [
    "! ctlearn -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f97eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ../my_outputs_stereo\n",
    "! ctlearn --default_model stackedTRN \\\n",
    "--input ../data/DL1_CTAO_public/ \\\n",
    "--pattern \"*.h5\" \\\n",
    "--tel_types LST_LST_LSTCam \\\n",
    "--reco type \\\n",
    "--allowed_tels 1 2 \\\n",
    "--multiplicity_cut 2 \\\n",
    "--size_cut 5000 \\\n",
    "--output ../my_outputs_stereo/my_first_stereo_training_mergedTRN_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbada97-1734-43ad-a810-bba9a51fe0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: ../my_outputs_stereo: File exists\n",
      "INFO:Logging has been correctly set up\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:Number of devices: 1\n",
      "INFO:Loading data:\n",
      "INFO:  For a large dataset, this may take a while...\n",
      "/Users/tjarkmiener/Desktop/ctlearn_workshop/ctlearn_workshop2024/software/dl1-data-handler/dl1_data_handler/reader.py:1207: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index([2], dtype='int64')]\n",
      "\n",
      "  pd.DataFrame(data=self.example_identifiers).to_hdf(\n",
      "/Users/tjarkmiener/Desktop/ctlearn_workshop/ctlearn_workshop2024/software/dl1-data-handler/dl1_data_handler/reader.py:1215: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->axis0] [items->None]\n",
      "\n",
      "  pd.DataFrame(\n",
      "/Users/tjarkmiener/Desktop/ctlearn_workshop/ctlearn_workshop2024/software/dl1-data-handler/dl1_data_handler/reader.py:1215: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block0_items] [items->None]\n",
      "\n",
      "  pd.DataFrame(\n",
      "INFO:  Number of events loaded: 36558\n",
      "INFO:Setting up model:\n",
      "INFO:  Constructing model from config.\n",
      "INFO:  Model has been correctly set up from config.\n",
      "WARNING:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "INFO:  Compiling model.\n",
      "INFO:Setting up training:\n",
      "INFO:  Validation split: 0.1\n",
      "INFO:  Number of epochs: 5\n",
      "INFO:  Size of the batches per worker: 16\n",
      "INFO:  Size of the batches: 16\n",
      "INFO:  Number of training steps per epoch: 2056\n",
      "INFO:  Optimizer: Adam\n",
      "INFO:  Learning rate: 0.0001\n",
      "INFO:  Learning rate reducing patience: 5\n",
      "INFO:  Learning rate reducing factor: 0.5\n",
      "INFO:  Learning rate reducing min delta: 0.01\n",
      "INFO:  Learning rate reducing min lr: 1e-05\n",
      "INFO:  Verbosity mode: 2\n",
      "INFO:  Number of workers: 1\n",
      "INFO:  Use of multiprocessing: False\n",
      "INFO:  Apply class weights:\n",
      "INFO:    Total number: 36558\n",
      "INFO:    Breakdown by 'gamma' (0) with original particle id '0': 17825\n",
      "INFO:    Breakdown by 'proton' (1) with original particle id '101': 18733\n",
      "INFO:    Class weights: {0: 1.0254698457223002, 1: 0.9757646933219453}\n",
      "INFO:Training and evaluating...\n",
      "2024-05-30 11:24:35.192845: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "Epoch 1/5\n",
      "2024-05-30 11:36:34.078198: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 4.37516, saving model to ../my_outputs/my_first_stereo_training_CNNRNN_type/ctlearn_model/\n",
      "INFO:tensorflow:Assets written to: ../my_outputs/my_first_stereo_training_CNNRNN_type/ctlearn_model/assets\n",
      "INFO:Assets written to: ../my_outputs/my_first_stereo_training_CNNRNN_type/ctlearn_model/assets\n",
      "2056/2056 - 748s - loss: 6.4573 - accuracy: 0.5006 - auc: 0.5010 - val_loss: 4.3752 - val_accuracy: 0.5181 - val_auc: 0.5040 - lr: 1.0000e-04 - 748s/epoch - 364ms/step\n",
      "Epoch 2/5\n",
      "2024-05-30 11:50:21.756429: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "\n",
      "Epoch 2: val_loss improved from 4.37516 to 2.16255, saving model to ../my_outputs/my_first_stereo_training_CNNRNN_type/ctlearn_model/\n",
      "INFO:tensorflow:Assets written to: ../my_outputs/my_first_stereo_training_CNNRNN_type/ctlearn_model/assets\n",
      "INFO:Assets written to: ../my_outputs/my_first_stereo_training_CNNRNN_type/ctlearn_model/assets\n",
      "2056/2056 - 827s - loss: 3.1871 - accuracy: 0.5061 - auc: 0.5057 - val_loss: 2.1626 - val_accuracy: 0.4868 - val_auc: 0.5018 - lr: 1.0000e-04 - 827s/epoch - 402ms/step\n",
      "Epoch 3/5\n",
      "2024-05-30 12:04:39.037228: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "\n",
      "Epoch 3: val_loss improved from 2.16255 to 1.18441, saving model to ../my_outputs/my_first_stereo_training_CNNRNN_type/ctlearn_model/\n",
      "INFO:tensorflow:Assets written to: ../my_outputs/my_first_stereo_training_CNNRNN_type/ctlearn_model/assets\n",
      "INFO:Assets written to: ../my_outputs/my_first_stereo_training_CNNRNN_type/ctlearn_model/assets\n",
      "2056/2056 - 860s - loss: 1.6086 - accuracy: 0.5082 - auc: 0.5103 - val_loss: 1.1844 - val_accuracy: 0.5167 - val_auc: 0.5115 - lr: 1.0000e-04 - 860s/epoch - 418ms/step\n",
      "2024-05-30 12:05:10.120300: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "Epoch 4/5\n"
     ]
    }
   ],
   "source": [
    "! mkdir ../my_outputs_stereo\n",
    "! ctlearn --default_model CNNRNN \\\n",
    "--input ../data/DL1_CTAO_public/ \\\n",
    "--pattern \"*.h5\" \\\n",
    "--tel_types LST_LST_LSTCam \\\n",
    "--reco type \\\n",
    "--output ../my_outputs/my_first_stereo_training_CNNRNN_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956ba6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a03ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ../my_outputs\n",
    "! ctlearn --default_model TRN \\\n",
    "--input ../data/DL1_CTAO_public/ \\\n",
    "--pattern \"*.h5\" \\\n",
    "--tel_types LST_LST_LSTCam \\\n",
    "--reco type \\\n",
    "--allowed_tels 1 2 \\\n",
    "--size_cut 5000 \\\n",
    "--num_epochs 5 \\\n",
    "--output ../my_outputs/my_first_PublicCTAO_training_type\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a55744",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ../my_outputs_stereo\n",
    "! ctlearn --default_model CNNRNN \\\n",
    "--input ../data/DL1_CTAO_public/ \\\n",
    "--pattern \"*.h5\" \\\n",
    "--tel_types LST_LST_LSTCam \\\n",
    "--reco type \\\n",
    "--allowed_tels 1 2 \\\n",
    "--multiplicity_cut 2 \\\n",
    "--size_cut 5000 \\\n",
    "--num_epochs 5 \\\n",
    "--pretrained_weights ../my_outputs/my_first_PublicCTAO_training_type \\\n",
    "--output ../my_outputs_stereo/my_first_TRNRNN_training_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406cec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
